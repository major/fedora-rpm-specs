# Generated by go2rpm 1.18.0
# go2rpm -p vendor -v 0.12.11 --name ollama github.com/ollama/ollama
%bcond check 0
%ifarch x86_64
%bcond rocm 1
%else
%bcond rocm 0
%endif
%bcond vulkan 0

# bundled GGML sources are missing ppc64le and s390x
ExcludeArch:    ppc64le s390x

# Build the next version of ollama
%bcond next 0

# systemd testing
%bcond systemd 1

# https://github.com/ollama/ollama
%global goipath         github.com/ollama/ollama
Version:                0.12.11

%gometa -L -f

Name:           ollama
Release:        %autorelease
Summary:        Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models

# Generated by go-vendor-tools
License:        Apache-2.0 AND BSD-2-Clause AND BSD-3-Clause AND BSD-3-Clause-HP AND BSL-1.0 AND CC-BY-3.0 AND CC-BY-4.0 AND CC0-1.0 AND ISC AND LicenseRef-Fedora-Public-Domain AND LicenseRef-scancode-protobuf AND MIT AND NCSA AND NTP AND OpenSSL AND ZPL-2.1 AND Zlib
URL:            %{gourl}
Source0:        %{gosource}
# Generated by go-vendor-tools
Source1:        %{archivename}-vendor.tar.bz2
Source2:        go-vendor-tools.toml
%if %{with systemd}
Source10:       ollama.service
Source11:       ollama.sysusers
%endif

Patch1:         0001-ollama-handle-load.patch

BuildRequires:  go-vendor-tools
BuildRequires:  fdupes
BuildRequires:  gcc-c++
BuildRequires:  cmake

%if %{with systemd}
BuildRequires:  systemd-rpm-macros
%endif

%if %{with rocm}
BuildRequires:  hipblas-devel
BuildRequires:  rocblas-devel
BuildRequires:  rocm-comgr-devel
BuildRequires:  rocm-compilersupport-macros
BuildRequires:  rocm-runtime-devel
BuildRequires:  rocm-hip-devel
BuildRequires:  rocm-rpm-macros
BuildRequires:  rocminfo
%endif

%if %{with vulkan}
BuildRequires:  vulkan-loader-devel
BuildRequires:  glslc
%endif

Requires:       %{name}-base%{?_isa} = %{version}-%{release}
%if %{with rocm}
Requires:       %{name}-rocm%{?_isa} = %{version}-%{release}
%endif
%if %{with vulkan}
Requires:       %{name}-vulkan%{?_isa} = %{version}-%{release}
%endif

%description
Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.

%package base
Summary:        The base ollama
%if %{with systemd}
%{?systemd_requires}
%endif

%description base
%{summary}

%if %{with rocm}
%package rocm
Summary:        The ROCm backend for ollama
Requires:       hipblas
Requires:       rocblas

%description rocm
%{summary}
%endif

%if %{with vulkan}
%package vulkan
Summary:        The Vulkan backend for ollama

%description vulkan
%{summary}
%endif


%prep
%goprep -A
%setup -q -T -D -a1 %{forgesetupargs}
%autopatch -p1

# Rename README's
mv app/README.md app-README.md
mv integration/README.md integration-README.md
mv llama/README.md llama-README.md

# No knob to turn off vulkan
%if %{without vulkan}
sed -i -e 's@Vulkan_FOUND@FALSE@' CMakeLists.txt
%endif

%generate_buildrequires
%go_vendor_license_buildrequires -c %{S:2}

%build

%cmake \
%if %{with rocm}
    -DCMAKE_HIP_COMPILER=%rocmllvm_bindir/clang++ \
    -DAMDGPU_TARGETS=%{rocm_gpu_list_default}
%endif

%cmake_build

%global gomodulesmode GO111MODULE=on

# Debug with:
# Manual build when there are problems
# export GOPATH=$(pwd)/_build:%{gopath}
# export GO111MODULE=off
# go build -o %{gobuilddir}/bin/ollama %{goipath}
# Release with
# cmake sets LDFLAGS env, this confuses gobuild
export LDFLAGS=
%gobuild -o %{gobuilddir}/bin/ollama %{goipath}

%install

%cmake_install

# remove copies of system libraries
runtime_removal="hipblas rocblas amdhip64 rocsolver amd_comgr hsa-runtime64 rocsparse tinfo rocprofiler-register drm drm_amdgpu numa elf vulkan"
for rr in $runtime_removal; do
    rm -rf %{buildroot}%{_prefix}/lib/ollama/lib${rr}*
done
rm -rf %{buildroot}%{_prefix}/lib/ollama/rocblas

mkdir -p %{buildroot}%{_bindir}
install -m 0755 -vp %{gobuilddir}/bin/ollama %{buildroot}%{_bindir}

rm -rf %{buildroot}%{_bindir}/*.so

%if %{with systemd}
install -p -D -m 0644 %{SOURCE10} %{buildroot}%{_unitdir}/ollama.service
install -p -D -m 0644 %{SOURCE11} %{buildroot}%{_sysusersdir}/ollama.conf
# home dir
mkdir -p %{buildroot}%{_var}/lib/ollama
%endif

%go_vendor_license_install -c %{S:2}
install -m 0755 -vd                     %{buildroot}%{_bindir}
install -m 0755 -vp %{gobuilddir}/bin/* %{buildroot}%{_bindir}/

%check
%go_vendor_license_check -c %{S:2}
%if %{with check}
%gotest ./...
%endif

%if %{with systemd}
%preun
%systemd_preun ollama.service

%post
%systemd_post ollama.service

%postun
%systemd_postun_with_restart ollama.service
%endif

%files
%doc README.md

%files -f %{go_vendor_license_filelist} base
%license vendor/modules.txt
%doc CONTRIBUTING.md SECURITY.md README.md app-README.md integration-README.md
%doc llama-README.md
%{_prefix}/lib/ollama/libggml-base.so
%ifarch x86_64
%{_prefix}/lib/ollama/libggml-cpu-alderlake.so
%{_prefix}/lib/ollama/libggml-cpu-haswell.so
%{_prefix}/lib/ollama/libggml-cpu-icelake.so
%{_prefix}/lib/ollama/libggml-cpu-sandybridge.so
%{_prefix}/lib/ollama/libggml-cpu-skylakex.so
%{_prefix}/lib/ollama/libggml-cpu-sse42.so
%{_prefix}/lib/ollama/libggml-cpu-x64.so
%else
# upstream CMakeLists.txt disables GGML CPU variants on aarch64
%{_prefix}/lib/ollama/libggml-cpu.so
%endif
%{_bindir}/ollama

%if %{with systemd}
%attr(0755,ollama,ollama) %dir  %{_var}/lib/ollama/
%{_unitdir}/ollama.service
%{_sysusersdir}/ollama.conf
%endif

%if %{with rocm}
%files rocm
%{_prefix}/lib/ollama/libggml-hip.so
%endif

%if %{with vulkan}
%files vulkan
%{_prefix}/lib/ollama/libggml-vulkan.so
%endif


%changelog
%autochangelog
